{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science for prediction machine:\n",
    "\n",
    "The data in the database came somewhat scrambled\n",
    "\n",
    "Problems with the original data:\n",
    "1. Incomplete (some values were missing in some rows)\n",
    "2. There are ',' inside some of the string values (this is a comma separated list)\n",
    "3. The dataset came with both parquet and csv files\n",
    "\n",
    "The first approach was to use the csv data loaded to python with pandas. The problem was that each year had more than 1.5 to 2.5Gb of data *each* so no laptop with 16Gb of ram could load such a dataset **in memory**. This lead to a clear path, use chunking (with the help of [dask](https://www.dask.org/)). Unfortunately (or fortunately, as well see next) this did not work, the \"read\" dataframe did not contain all of the information. \n",
    "\n",
    "In trying to figure out if dask or the csv was the problem we tried to merge the data from 2 different years and get some data from it with linux tools (it seems that python does not like to parse and write more than 10 million records) such as [awk](https://en.wikipedia.org/wiki/AWK), [uniq](https://en.wikipedia.org/wiki/Uniq), etc... What we found was that some of the string data contained the same character that was used to as the separator in the file (','). \n",
    "\n",
    "So, after much work trying to wrangle the data in the csvs to no avail (no parser did the job correctly) we tried to see what these [.parquet](https://parquet.apache.org/) files were. As it seems they are a columnar file (from apache) that does not store all of the data as strings. What this does is reduce the size need to store the data manyfold. To give an example our dataset consisting of two years wasted 3.6Gb of space as csv but has parquet occupied just under 400Mb. Nothing is a silver bullet tho and, as a last gripe by the gods against me, while merging the two parquet files I found that the values of one single column were set as `int64` in one table and `float64` in another... Fortunately this had a decently straightforward solution (casting one of the tables according to the schema of the other).\n",
    "\n",
    "We can **finally** load the data into memory to see what it is..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo:\n",
    "\n",
    "1. Understand what columns are import\n",
    "2. Remove the rest\n",
    "3. Save the new file and send it to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets load the dataset:\n",
    "flights = pd.read_parquet(\"../../dataset/flights.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FlightDate' 'Airline' 'Origin' 'Dest' 'Cancelled' 'Diverted'\n",
      " 'CRSDepTime' 'DepTime' 'DepDelayMinutes' 'DepDelay' 'ArrTime'\n",
      " 'ArrDelayMinutes' 'AirTime' 'CRSElapsedTime' 'ActualElapsedTime'\n",
      " 'Distance' 'Year' 'Quarter' 'Month' 'DayofMonth' 'DayOfWeek'\n",
      " 'Marketing_Airline_Network' 'Operated_or_Branded_Code_Share_Partners'\n",
      " 'DOT_ID_Marketing_Airline' 'IATA_Code_Marketing_Airline'\n",
      " 'Flight_Number_Marketing_Airline' 'Operating_Airline'\n",
      " 'DOT_ID_Operating_Airline' 'IATA_Code_Operating_Airline' 'Tail_Number'\n",
      " 'Flight_Number_Operating_Airline' 'OriginAirportID' 'OriginAirportSeqID'\n",
      " 'OriginCityMarketID' 'OriginCityName' 'OriginState' 'OriginStateFips'\n",
      " 'OriginStateName' 'OriginWac' 'DestAirportID' 'DestAirportSeqID'\n",
      " 'DestCityMarketID' 'DestCityName' 'DestState' 'DestStateFips'\n",
      " 'DestStateName' 'DestWac' 'DepDel15' 'DepartureDelayGroups' 'DepTimeBlk'\n",
      " 'TaxiOut' 'WheelsOff' 'WheelsOn' 'TaxiIn' 'CRSArrTime' 'ArrDelay'\n",
      " 'ArrDel15' 'ArrivalDelayGroups' 'ArrTimeBlk' 'DistanceGroup'\n",
      " 'DivAirportLandings']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_699/1421152036.py:4: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  flights.describe(exclude=np.number)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FlightDate</th>\n",
       "      <th>Airline</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>Marketing_Airline_Network</th>\n",
       "      <th>Operated_or_Branded_Code_Share_Partners</th>\n",
       "      <th>IATA_Code_Marketing_Airline</th>\n",
       "      <th>Operating_Airline</th>\n",
       "      <th>IATA_Code_Operating_Airline</th>\n",
       "      <th>Tail_Number</th>\n",
       "      <th>OriginCityName</th>\n",
       "      <th>OriginState</th>\n",
       "      <th>OriginStateName</th>\n",
       "      <th>DestCityName</th>\n",
       "      <th>DestState</th>\n",
       "      <th>DestStateName</th>\n",
       "      <th>DepTimeBlk</th>\n",
       "      <th>ArrTimeBlk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10390189</td>\n",
       "      <td>10390189</td>\n",
       "      <td>10390189</td>\n",
       "      <td>10390189</td>\n",
       "      <td>10390189</td>\n",
       "      <td>10390189</td>\n",
       "      <td>10390189</td>\n",
       "      <td>10390189</td>\n",
       "      <td>10390189</td>\n",
       "      <td>10390189</td>\n",
       "      <td>10390189</td>\n",
       "      <td>10340091</td>\n",
       "      <td>10390189</td>\n",
       "      <td>10390189</td>\n",
       "      <td>10390189</td>\n",
       "      <td>10390189</td>\n",
       "      <td>10390189</td>\n",
       "      <td>10390189</td>\n",
       "      <td>10390189</td>\n",
       "      <td>10390189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>577</td>\n",
       "      <td>22</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>6015</td>\n",
       "      <td>374</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>374</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2021-11-28 00:00:00</td>\n",
       "      <td>Southwest Airlines Co.</td>\n",
       "      <td>ATL</td>\n",
       "      <td>ATL</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>AA</td>\n",
       "      <td>WN</td>\n",
       "      <td>AA</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>N480HA</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>TX</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>TX</td>\n",
       "      <td>Texas</td>\n",
       "      <td>0800-0859</td>\n",
       "      <td>1600-1659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>21331</td>\n",
       "      <td>1796565</td>\n",
       "      <td>496984</td>\n",
       "      <td>496952</td>\n",
       "      <td>10155979</td>\n",
       "      <td>10364997</td>\n",
       "      <td>2717901</td>\n",
       "      <td>1796565</td>\n",
       "      <td>2717901</td>\n",
       "      <td>1796565</td>\n",
       "      <td>1796565</td>\n",
       "      <td>4474</td>\n",
       "      <td>563572</td>\n",
       "      <td>1125459</td>\n",
       "      <td>1125459</td>\n",
       "      <td>563552</td>\n",
       "      <td>1125337</td>\n",
       "      <td>1125337</td>\n",
       "      <td>733885</td>\n",
       "      <td>678128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>2022-07-31 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 FlightDate                 Airline    Origin      Dest  \\\n",
       "count              10390189                10390189  10390189  10390189   \n",
       "unique                  577                      22       380       380   \n",
       "top     2021-11-28 00:00:00  Southwest Airlines Co.       ATL       ATL   \n",
       "freq                  21331                 1796565    496984    496952   \n",
       "first   2021-01-01 00:00:00                     NaN       NaN       NaN   \n",
       "last    2022-07-31 00:00:00                     NaN       NaN       NaN   \n",
       "\n",
       "       Cancelled  Diverted Marketing_Airline_Network  \\\n",
       "count   10390189  10390189                  10390189   \n",
       "unique         2         2                        10   \n",
       "top        False     False                        AA   \n",
       "freq    10155979  10364997                   2717901   \n",
       "first        NaN       NaN                       NaN   \n",
       "last         NaN       NaN                       NaN   \n",
       "\n",
       "       Operated_or_Branded_Code_Share_Partners IATA_Code_Marketing_Airline  \\\n",
       "count                                 10390189                    10390189   \n",
       "unique                                      15                          10   \n",
       "top                                         WN                          AA   \n",
       "freq                                   1796565                     2717901   \n",
       "first                                      NaN                         NaN   \n",
       "last                                       NaN                         NaN   \n",
       "\n",
       "       Operating_Airline IATA_Code_Operating_Airline Tail_Number  \\\n",
       "count           10390189                    10390189    10340091   \n",
       "unique                22                          22        6015   \n",
       "top                   WN                          WN      N480HA   \n",
       "freq             1796565                     1796565        4474   \n",
       "first                NaN                         NaN         NaN   \n",
       "last                 NaN                         NaN         NaN   \n",
       "\n",
       "       OriginCityName OriginState OriginStateName DestCityName DestState  \\\n",
       "count        10390189    10390189        10390189     10390189  10390189   \n",
       "unique            374          53              53          374        53   \n",
       "top       Chicago, IL          TX           Texas  Chicago, IL        TX   \n",
       "freq           563572     1125459         1125459       563552   1125337   \n",
       "first             NaN         NaN             NaN          NaN       NaN   \n",
       "last              NaN         NaN             NaN          NaN       NaN   \n",
       "\n",
       "       DestStateName DepTimeBlk ArrTimeBlk  \n",
       "count       10390189   10390189   10390189  \n",
       "unique            53         19         19  \n",
       "top            Texas  0800-0859  1600-1659  \n",
       "freq         1125337     733885     678128  \n",
       "first            NaN        NaN        NaN  \n",
       "last             NaN        NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And see what columns we are working with:\n",
    "print(flights.columns.values)\n",
    "\n",
    "flights.describe(exclude=np.number)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these are obviously important while other are the exact opposite:\n",
    "\n",
    "Very Important:\n",
    "1. FlightDate\n",
    "2. Airline\n",
    "3. Origin\n",
    "4. Dest\n",
    "5. Cancelled\n",
    "6. Diverted\n",
    "7. CRSDepTime (scheduled dep time)\n",
    "8. DepTime (actual dep time)\n",
    "9. DepDelay\n",
    "10. CRSArrTime (scheduled arrival time)\n",
    "11. ArrTime (actual arrival time)\n",
    "12. ArrDelay\n",
    "13. Flight_Number_Operating_Airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FlightDate', 'Airline', 'Operating_Airline', 'Origin', 'Dest',\n",
       "       'AirTime', 'Cancelled', 'Diverted', 'CRSDepTime', 'DepTime',\n",
       "       'DepDelay', 'CRSArrTime', 'ArrTime', 'ArrDelay', 'OriginAirportID',\n",
       "       'DestAirportID', 'Tail_Number', 'CRSElapsedTime',\n",
       "       'Flight_Number_Operating_Airline'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can separate these out:\n",
    "\n",
    "important_columns = [\"FlightDate\",\n",
    "                     \"Airline\",\n",
    "                     \"Operating_Airline\",\n",
    "                     \"Origin\",\n",
    "                     \"Dest\",\n",
    "                     \"AirTime\",\n",
    "                     \"Cancelled\",\n",
    "                     \"Diverted\",\n",
    "                     \"CRSDepTime\",\n",
    "                     \"DepTime\",\n",
    "                     \"DepDelay\",\n",
    "                     \"CRSArrTime\",\n",
    "                     \"ArrTime\",\n",
    "                     \"ArrDelay\",\n",
    "                     \"OriginAirportID\",\n",
    "                     \"DestAirportID\",\n",
    "                     \"Tail_Number\",\n",
    "                     \"CRSElapsedTime\",\n",
    "                     \"Flight_Number_Operating_Airline\"]\n",
    "\n",
    "flight_data = flights[important_columns]\n",
    "\n",
    "flight_data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And save as new file\n",
    "\n",
    "flight_data.to_parquet('../../dataset/flight-data.parquet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Needed links\n",
    "\n",
    "1. https://stackoverflow.com/questions/34682828/extracting-specific-selected-columns-to-new-dataframe-as-a-copy\n",
    "2. https://pandas.pydata.org/pandas-docs/version/1.1/reference/api/pandas.DataFrame.to_parquet.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
